{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kafka Consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c92e614d-6dd6-40bd-9a49-6b85ce981a00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def error_cb(err):\n",
    "    \"\"\" The error callback is used for generic client errors. These\n",
    "        errors are generally to be considered informational as the client will\n",
    "        automatically try to recover from all errors, and no extra action\n",
    "        is typically required by the application.\n",
    "        For this example however, we terminate the application if the client\n",
    "        is unable to connect to any broker (_ALL_BROKERS_DOWN) and on\n",
    "        authentication errors (_AUTHENTICATION). \"\"\"\n",
    "\n",
    "    print(\"Client error: {}\".format(err))\n",
    "    if err.code() == KafkaError._ALL_BROKERS_DOWN or \\\n",
    "       err.code() == KafkaError._AUTHENTICATION:\n",
    "        # Any exception raised from this callback will be re-raised from the\n",
    "        # triggering flush() or poll() call.\n",
    "        raise KafkaException(err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting Consumer Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f404b3f4-2a72-4439-8367-e6564443e5fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from time import sleep\n",
    "import uuid\n",
    "from confluent_kafka import Producer, Consumer, KafkaError, KafkaException\n",
    "import json\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pandas as pd\n",
    "\n",
    "#KAFKA variables\n",
    "confluentClusterName = config.confluentClusterName\n",
    "confluentBootstrapServers = config.confluentBootstrapServers\n",
    "confluentTopicName = config.confluentTopicName\n",
    "schemaRegistryUrl = config.schemaRegistryUrl\n",
    "confluentApiKey = config.confluentApiKey\n",
    "confluentSecret = config.confluentSecret\n",
    "confluentRegistryApiKey = config.confluentRegistryApiKey\n",
    "confluentRegistrySecret = config.confluentRegistrySecret\n",
    "\n",
    "#Kakfa Class Setup.\n",
    "c = Consumer({\n",
    "    'bootstrap.servers': confluentBootstrapServers,\n",
    "    'sasl.mechanism': 'PLAIN',\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.username': confluentApiKey,\n",
    "    'sasl.password': confluentSecret,\n",
    "    'group.id': str(uuid.uuid1()),  # this will create a new consumer group on each invocation.\n",
    "    'auto.offset.reset': 'earliest',\n",
    "    'error_cb': error_cb,\n",
    "})\n",
    "\n",
    "c.subscribe(['diabetesfinal-10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Consumer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9385c494-54fe-404d-b9b7-63841a1ad8bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">1635538253086 file1 saved\n",
       "1635538390318 file2 saved\n",
       "1635538527545 file3 saved\n",
       "1635538664636 file4 saved\n",
       "1635538801994 file5 saved\n",
       "1635538939186 file6 saved\n",
       "1635539076547 file7 saved\n",
       "1635539213489 file8 saved\n",
       "1635539350668 file9 saved\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">1635538253086 file1 saved\n1635538390318 file2 saved\n1635538527545 file3 saved\n1635538664636 file4 saved\n1635538801994 file5 saved\n1635538939186 file6 saved\n1635539076547 file7 saved\n1635539213489 file8 saved\n1635539350668 file9 saved\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kafkaListDictionaries = []             \n",
    "while(True): \n",
    "    try:\n",
    "        msg = c.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            break\n",
    "        elif msg.error():\n",
    "            print(\"Consumer error: {}\".format(msg.error()))\n",
    "            pass\n",
    "        else:\n",
    "            df_dict=json.loads('{}'.format(msg.value().decode('utf-8')))          \n",
    "            kafkaListDictionaries.append(df_dict)                             #Store dictionary message in list \"kafkaListDictionaries\"  \n",
    "            sleep(0.3)\n",
    "            del df_dict\n",
    "        \n",
    "            if len(kafkaListDictionaries) > 500:                              #When list exceeds 500 items, save list as csv file\n",
    "                df = pd.DataFrame(kafkaListDictionaries)\n",
    "                df.drop_duplicates()\n",
    "                time = str(msg.timestamp()[1])\n",
    "                filepath = r'/dbfs/mnt/eddydoering/diabeetus/consumer_final/diabetesfinal-4/' + time + \".csv\"    #name csv file based on timestamp\n",
    "                df.to_csv(filepath, index=False)         \n",
    "                kafkaListDictionaries = []\n",
    "            \n",
    "                     \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "df = pd.DataFrame(kafkaListDictionaries)                     #When no messages remain, save leftover messages as csv\n",
    "df.drop_duplicates()\n",
    "filepath = r'/dbfs/mnt/eddydoering/diabeetus/consumer_final/diabetesfinal-3/' + \"final.csv\"\n",
    "df.to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "capstone_consumer",
   "notebookOrigID": 4035785737179582,
   "widgets": {}
  },
  "interpreter": {
   "hash": "f0aeb945a0f4941527bbb9f5e68988ff233b4c4d67ade5fbe62231d824151796"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
